{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape Titled Tuesday Game Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tourn_links = pd.read_pickle('../output/Chess.com/tourn_links.pkl')\n",
    "except: \n",
    "    tt = 'https://www.chess.com/tournament/live/titled-tuesdays'\n",
    "    tourn_links = []\n",
    "    for i in range(6):\n",
    "        r = requests.get(tt+'?&page='+str(i+1))\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        tourn_list = soup.find('table', class_ = 'table-component table-hover table-clickable tournaments-live-table')\n",
    "        tourn_table_rows = tourn_list.find_all('tr')\n",
    "        tourn_table_rows = tourn_table_rows[1:]\n",
    "        for j in tourn_table_rows:\n",
    "            tourn_link = j.find('a', class_='tournaments-live-name')['href']\n",
    "            tourn_links.append(tourn_link)\n",
    "        with open('tourn_links.pkl', 'wb') as f:\n",
    "            pickle.dump(tourn_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourn_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourn_links[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get final results data, save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in tourn_links:\n",
    "    parts = url.split('/')\n",
    "    tournament_id = parts[-1]\n",
    "    output_filename = f\"{tournament_id}.csv\"\n",
    "    \n",
    "    if os.path.exists(output_filename):\n",
    "        print(\"File already exists: \" + output_filename)\n",
    "        continue\n",
    "    \n",
    "    r = requests.get(url+'?&players=100')\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    i_p = soup.find('div', class_ = 'index-pagination')\n",
    "    data_total_pages = 0\n",
    "    \n",
    "    if i_p:\n",
    "        data_total_pages = int(i_p.find('div')['data-total-pages'])\n",
    "    print(\"total pages: \" + str(data_total_pages))\n",
    "\n",
    "    ranks = []\n",
    "    rank = 0\n",
    "    for i in range(data_total_pages):\n",
    "        print('page: ' + str(i+1))\n",
    "        r = requests.get(url+'?&players='+str(i+1))\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        table = soup.find('table', class_ = 'table-component tournaments-live-view-results-table tournaments-live-view-extra-borders')\n",
    "        table_rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "\n",
    "        for x in table_rows:\n",
    "            rank += 1\n",
    "            if rank % 100 == 0:\n",
    "                print(\"completed: \" + str(rank))\n",
    "            \n",
    "            username = x.select_one('.user-tagline-username').get_text(strip=True)\n",
    "            country = x.select_one('.country-flags-component')['v-tooltip']\n",
    "            rating = x.select_one('.user-rating').get_text(strip=True).replace('(', '').replace(')', '')\n",
    "            if rating != 'Unrated':\n",
    "                rating = int(rating)\n",
    "            title_element = x.select_one('.post-view-meta-title')\n",
    "            title = title_element.get_text(strip=True) if title_element is not None else None\n",
    "            score = float(x.select_one('.tournaments-live-view-total-score').get_text(strip=True))\n",
    "            tie_break = float(x.select_one('.tournaments-live-view-tie-break').get_text(strip=True))\n",
    "            wdb = x.find('div', class_='tournaments-live-view-total-score')['v-tooltip'].split(',')\n",
    "            wins = int(wdb[0].strip().split()[0])\n",
    "            draws = int(wdb[1].strip().split()[0])\n",
    "            byes = int(wdb[2].strip().split()[0])\n",
    "            \n",
    "            player = {\n",
    "                \"rank\": rank,\n",
    "                \"username\": username,\n",
    "                \"country\": country,\n",
    "                \"rating\": rating,\n",
    "                \"title\": title,\n",
    "                \"score\": score,\n",
    "                \"tie_break\": tie_break,\n",
    "                \"wins\": wins,\n",
    "                \"draws\": draws,\n",
    "                \"byes\": byes\n",
    "            }\n",
    "            ranks.append(player)\n",
    "\n",
    "    df = pd.DataFrame(ranks)\n",
    "    \n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(\"written: \" + output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairings Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get pairings data, save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in tourn_links:\n",
    "    parts = url.split('/')\n",
    "    tournament_id = parts[-1]\n",
    "    output_filename = f\"../output/Chess.com/Titled Tuesday Pairings/{tournament_id}_pairings.csv\"\n",
    "    \n",
    "    if os.path.exists(output_filename):\n",
    "        print(\"File already exists: \" + output_filename)\n",
    "        continue\n",
    "    \n",
    "    r = requests.get(url+'?&players=100')\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    i_p = soup.find('div', class_ = 'index-pagination')\n",
    "    data_total_pages = 0\n",
    "    \n",
    "    if i_p:\n",
    "        data_total_pages = int(i_p.find('div')['data-total-pages'])\n",
    "    print(\"total pages: \" + str(data_total_pages))\n",
    "\n",
    "    matches = []\n",
    "    rank = 0\n",
    "\n",
    "    # for each of the 11 rounds\n",
    "    for i in range(12):\n",
    "        #print('page: ' + str(i+1))\n",
    "        r = requests.get(url+'?&round='+str(i+1)) # pick round i url\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "        table = soup.find('table', class_ = 'table-component table-hover tournaments-live-view-pairings-table') # pairings table\n",
    "        table_rows = table.find_all('tr')[1:] # row from table\n",
    "\n",
    "        # for each row in this round's table\n",
    "        for x in table_rows:\n",
    "            rank += 1\n",
    "            if rank % 100 == 0:\n",
    "                print(\"completed: \" + str(rank))\n",
    "            \n",
    "            player_1_status = x.select_one('td:first-of-type .post-view-meta-title').text.strip() if x.select_one('td:first-of-type .post-view-meta-title') else None\n",
    "            player_1_username = x.select_one('td:first-of-type .user-tagline-username').text.strip()\n",
    "            player_1_elo = x.select_one('td:first-of-type .user-rating').text.strip(\"()\")\n",
    "\n",
    "            result = x.select_one('td:nth-of-type(2)').text.strip()\n",
    "\n",
    "            player_2_status = x.select_one('td:last-of-type .post-view-meta-title').text.strip() if x.select_one('td:last-of-type .post-view-meta-title') else None\n",
    "            player_2_username = x.select_one('td:last-of-type .user-tagline-username').text.strip()\n",
    "            player_2_elo = x.select_one('td:last-of-type .user-rating').text.strip(\"()\")\n",
    "            \n",
    "            match = {\n",
    "                \"white_rank\": player_1_status,\n",
    "                \"white_username\": player_1_username,\n",
    "                \"white_elo\": player_1_elo,\n",
    "                \"result\": result,\n",
    "                \"black_rank\": player_2_status,\n",
    "                \"black_username\": player_2_username,\n",
    "                \"black_elo\": player_2_elo\n",
    "            }\n",
    "            matches.append(match)\n",
    "\n",
    "    df = pd.DataFrame(matches)\n",
    "    df = df.drop_duplicates()\n",
    "    #display(df.head(2))\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(\"written: \" + output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
